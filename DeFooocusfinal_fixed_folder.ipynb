{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Filarh/Hello-World/blob/master/DeFooocusfinal_fixed_folder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aWA1uOTLmDUf",
        "outputId": "17c86f89-c28b-4502-e347-839faa88bda8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "\u001b[92mUsing default.json as a reference\u001b[0m\n",
            "Created art.json with the provided parameters and structure!\n",
            "\u001b[96mFile art.safetensors already exists. No download required.\u001b[0m\n",
            "\u001b[92mModel downloaded: /content/DeFooocus/models/checkpoints/art.safetensors\u001b[0m\n",
            "\u001b[95m[DeFooocus] Preparing...\u001b[0m\n",
            "\u001b[95m[DeFooocus] Starting...\u001b[0m\n",
            "Already up-to-date\n",
            "Update succeeded.\n",
            "[System ARGV] ['entry_with_update.py', '--share', '--attention-split', '--always-high-vram', '--disable-offload-from-vram', '--all-in-fp16', '--theme', 'dark', '--preset', 'art']\n",
            "Python 3.10.12 (main, Sep 11 2024, 15:47:36) [GCC 11.4.0]\n",
            "Fooocus version: 0.2\n",
            "Loaded preset: /content/DeFooocus/presets/art.json\n",
            "Total VRAM 15102 MB, total RAM 12979 MB\n",
            "Forcing FP16.\n",
            "Set vram state to: HIGH_VRAM\n",
            "Device: cuda:0 Tesla T4 : native\n",
            "VAE dtype: torch.float32\n",
            "Using split optimization for cross attention\n",
            "2024-11-13 18:55:36.657340: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-11-13 18:55:36.685213: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-11-13 18:55:36.693807: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-11-13 18:55:38.247675: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Refiner unloaded.\n",
            "IMPORTANT: You are using gradio version 3.41.2, however version 4.44.1 is available, please upgrade.\n",
            "--------\n",
            "Running on local URL:  http://127.0.0.1:7865\n",
            "model_type EPS\n",
            "UNet ADM Dimension 2816\n",
            "Running on public URL: https://d338f6368c55e7b7fd.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n",
            "Using split attention in VAE\n",
            "Working with z of shape (1, 4, 32, 32) = 4096 dimensions.\n",
            "Using split attention in VAE\n",
            "extra {'cond_stage_model.clip_l.text_projection', 'cond_stage_model.clip_l.logit_scale', 'cond_stage_model.clip_g.transformer.text_model.embeddings.position_ids'}\n",
            "loaded straight to GPU\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.12 seconds\n",
            "Base model loaded: /content/DeFooocus/models/checkpoints/art.safetensors\n",
            "Request to load LoRAs [['sd_xl_offset_example-lora_1.0.safetensors', 0.1], ['None', 1.0], ['None', 1.0], ['None', 1.0], ['None', 1.0]] for model [/content/DeFooocus/models/checkpoints/art.safetensors].\n",
            "Loaded LoRA [/content/drive/MyDrive/MyLoras/sd_xl_offset_example-lora_1.0.safetensors] for UNet [/content/DeFooocus/models/checkpoints/art.safetensors] with 788 keys at weight 0.1.\n",
            "Fooocus V2 Expansion: Vocab with 642 words.\n",
            "/content/DeFooocus/modules/patch.py:465: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  result = original_loader(*args, **kwargs)\n",
            "Fooocus Expansion engine loaded for cuda:0, use_fp16 = True.\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.59 seconds\n",
            "/usr/local/lib/python3.10/dist-packages/diffusers/utils/outputs.py:63: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
            "  torch.utils._pytree._register_pytree_node(\n",
            "Started worker with PID 4782\n",
            "App started successful. Use the app with http://127.0.0.1:7865/ or 127.0.0.1:7865 or https://d338f6368c55e7b7fd.gradio.live\n",
            "[Parameters] Adaptive CFG = 7\n",
            "[Parameters] Sharpness = 2\n",
            "[Parameters] ControlNet Softness = 0.25\n",
            "[Parameters] ADM Scale = 1.5 : 0.8 : 0.3\n",
            "[Parameters] CFG = 4.0\n",
            "[Parameters] Seed = 3625838078805568510\n",
            "[Fooocus] Downloading control models ...\n",
            "Downloading: \"https://huggingface.co/lllyasviel/misc/resolve/main/fooocus_xl_cpds_128.safetensors\" to /content/DeFooocus/models/controlnet/fooocus_xl_cpds_128.safetensors\n",
            "\n",
            "100% 377M/377M [00:01<00:00, 233MB/s]\n",
            "[Fooocus] Loading control models ...\n",
            "[Parameters] Sampler = dpmpp_2m_sde_gpu - karras\n",
            "[Parameters] Steps = 45 - 22\n",
            "[Fooocus] Initializing ...\n",
            "[Fooocus] Loading models ...\n",
            "Refiner unloaded.\n",
            "[Fooocus] Processing prompts ...\n",
            "[Fooocus] Encoding positive #1 ...\n",
            "[Fooocus] Encoding positive #2 ...\n",
            "[Fooocus] Encoding positive #3 ...\n",
            "[Fooocus] Encoding positive #4 ...\n",
            "[Fooocus] Encoding positive #5 ...\n",
            "[Fooocus] Encoding positive #6 ...\n",
            "[Fooocus] Encoding positive #7 ...\n",
            "[Fooocus] Encoding positive #8 ...\n",
            "[Fooocus] Encoding negative #1 ...\n",
            "[Fooocus] Encoding negative #2 ...\n",
            "[Fooocus] Encoding negative #3 ...\n",
            "[Fooocus] Encoding negative #4 ...\n",
            "[Fooocus] Encoding negative #5 ...\n",
            "[Fooocus] Encoding negative #6 ...\n",
            "[Fooocus] Encoding negative #7 ...\n",
            "[Fooocus] Encoding negative #8 ...\n",
            "[Fooocus] Image processing ...\n",
            "[Parameters] Denoising Strength = 1.0\n",
            "[Parameters] Initial Latent shape: Image Space (1024, 1024)\n",
            "Preparation time: 5.27 seconds\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "/content/DeFooocus/modules/patch.py:465: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  result = original_loader(*args, **kwargs)\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "unload clone 2\n",
            "[Fooocus Model Management] Moving model(s) has taken 1.87 seconds\n",
            "  9% 4/45 [00:10<01:46,  2.61s/it]"
          ]
        }
      ],
      "source": [
        "# Check if 'Args' is in the local scope\n",
        "if 'Args' not in locals():\n",
        "    # Install dependencies if necessary\n",
        "    !apt install -y aria2\n",
        "    !pip install pygit2==1.12.2\n",
        "    %cd /content\n",
        "    !git clone https://github.com/ehristoforu/DeFooocus.git\n",
        "    %cd /content/DeFooocus\n",
        "    Args = \"\"\n",
        "\n",
        "# Import necessary libraries\n",
        "import os\n",
        "import json\n",
        "from google.colab import drive\n",
        "\n",
        "# Fix: Create the 'cached_download' folder in the 'huggingface_hub' path if it doesn't exist\n",
        "import sys\n",
        "huggingface_hub_path = '/usr/local/lib/python3.10/dist-packages/huggingface_hub'\n",
        "cached_download_path = os.path.join(huggingface_hub_path, \"cached_download\")\n",
        "if not os.path.exists(cached_download_path):\n",
        "    os.makedirs(cached_download_path)\n",
        "\n",
        "# Function to print in color (Colab compatible)\n",
        "def print_colored(text, color):\n",
        "    color_codes = {\n",
        "        \"red\": \"\\033[91m\",\n",
        "        \"green\": \"\\033[92m\",\n",
        "        \"yellow\": \"\\033[93m\",\n",
        "        \"blue\": \"\\033[94m\",\n",
        "        \"magenta\": \"\\033[95m\",\n",
        "        \"cyan\": \"\\033[96m\",\n",
        "        \"white\": \"\\033[97m\",\n",
        "        \"reset\": \"\\033[0m\"\n",
        "    }\n",
        "    print(f\"{color_codes.get(color, color_codes['reset'])}{text}{color_codes['reset']}\")\n",
        "\n",
        "# Function to modify JSON with provided parameters\n",
        "def modificar_json(nombre_archivo: str, link_archivo: str, aspect_ratio: str, formato: str):\n",
        "    carpeta = '/content/DeFooocus/presets'\n",
        "    archivos = os.listdir(carpeta)\n",
        "\n",
        "    json_encontrado = None\n",
        "    if 'default.json' in archivos:\n",
        "        json_encontrado = 'default.json'\n",
        "        print_colored(\"Using default.json as a reference\", \"green\")\n",
        "    else:\n",
        "        json_encontrado = next((archivo for archivo in archivos if archivo.endswith('.json')), None)\n",
        "        print_colored(\"No default.json found, using a random JSON file.\", \"yellow\")\n",
        "\n",
        "    if json_encontrado:\n",
        "        with open(os.path.join(carpeta, json_encontrado)) as file:\n",
        "            data = json.load(file)\n",
        "\n",
        "        archivo_modelo = f\"{nombre_archivo}.{formato}\"\n",
        "        data['default_model'] = archivo_modelo\n",
        "        data['default_aspect_ratio'] = aspect_ratio\n",
        "        data['default_refiner'] = \"\"\n",
        "\n",
        "        data['checkpoint_downloads'] = {archivo_modelo: link_archivo}\n",
        "\n",
        "        global Args\n",
        "        Args = f\"--preset {nombre_archivo}\"\n",
        "\n",
        "        nuevo_nombre = f\"{nombre_archivo}.json\"\n",
        "        with open(os.path.join(carpeta, nuevo_nombre), 'w') as file:\n",
        "            json.dump(data, file, separators=(',', ':'))\n",
        "\n",
        "        return f\"Created {nuevo_nombre} with the provided parameters and structure!\"\n",
        "    else:\n",
        "        return \"No JSON files found in the specified folder.\"\n",
        "\n",
        "# Function to download the model using aria2 if it does not exist\n",
        "def download_model_aria2(url, nombre_archivo, formato, tokenCIVITAI, tokenHUGGINGFACE):\n",
        "    try:\n",
        "        model_dir = \"/content/DeFooocus/models/checkpoints\"\n",
        "        if not os.path.exists(model_dir):\n",
        "            os.makedirs(model_dir)\n",
        "\n",
        "        archivo_modelo = f\"{nombre_archivo}.{formato}\"\n",
        "        destino = os.path.join(model_dir, archivo_modelo)\n",
        "\n",
        "        if os.path.exists(destino):\n",
        "            print_colored(f\"File {archivo_modelo} already exists. No download required.\", \"cyan\")\n",
        "            return destino\n",
        "\n",
        "        if \"huggingface\" in url and tokenHUGGINGFACE:\n",
        "            url += f\"&token={tokenHUGGINGFACE}\"\n",
        "        elif \"civitai\" in url and tokenCIVITAI:\n",
        "            url += f\"&token={tokenCIVITAI}\"\n",
        "\n",
        "        download_command = f'aria2c -x 16 -s 16 -k 1M \"{url}\" -d \"{model_dir}\" -o \"{archivo_modelo}\"'\n",
        "\n",
        "        print_colored(f\"Downloading from URL: {download_command}\", \"blue\")\n",
        "        os.system(download_command)\n",
        "\n",
        "        if os.path.exists(destino):\n",
        "            print_colored(f\"Downloaded file at: {destino}\", \"green\")\n",
        "            return destino\n",
        "        else:\n",
        "            print_colored(\"Failed to download file.\", \"red\")\n",
        "            return None\n",
        "\n",
        "    except Exception as e:\n",
        "        print_colored(f\"Download error: {e}\", \"red\")\n",
        "        return None\n",
        "\n",
        "# Activating Google Drive if necessary\n",
        "activar_drive = True\n",
        "if activar_drive:\n",
        "    drive.mount('/content/drive')\n",
        "    nuevo_dir_lora = '/content/drive/MyDrive/MyLoras'\n",
        "    nuevo_dir_salida = '/content/drive/MyDrive/Fooocus_output'\n",
        "\n",
        "    launch_py_path = '/content/DeFooocus/launch.py'\n",
        "\n",
        "    if os.path.exists(launch_py_path):\n",
        "        with open(launch_py_path, 'r') as file:\n",
        "            launch_py_content = file.read()\n",
        "\n",
        "        codigo_a_insertar = f'''\n",
        "import os\n",
        "import json\n",
        "\n",
        "nuevo_dir_lora = '{nuevo_dir_lora}'\n",
        "nuevo_dir_salida = '{nuevo_dir_salida}'\n",
        "\n",
        "config_path = os.path.abspath(\"./config.txt\")\n",
        "config_dict = {{}}\n",
        "\n",
        "if os.path.exists(config_path):\n",
        "    with open(config_path, \"r\", encoding=\"utf-8\") as json_file:\n",
        "        config_dict = json.load(json_file)\n",
        "\n",
        "config_dict['path_loras'] = os.path.abspath(nuevo_dir_lora)\n",
        "config_dict['path_outputs'] = os.path.abspath(nuevo_dir_salida)\n",
        "\n",
        "with open(config_path, \"w\", encoding=\"utf-8\") as json_file:\n",
        "    json.dump(config_dict, json_file, indent=4)\n",
        "'''\n",
        "\n",
        "        if codigo_a_insertar not in launch_py_content:\n",
        "            with open(launch_py_path, 'w') as file:\n",
        "                file.write(codigo_a_insertar + launch_py_content)\n",
        "        else:\n",
        "            print_colored(\"Code already inserted in launch.py\", \"cyan\")\n",
        "    else:\n",
        "        print_colored(\"launch.py file not found.\", \"red\")\n",
        "\n",
        "# JSON model modification\n",
        "modificar_modelo = True\n",
        "nombre_archivo = \"art\"\n",
        "link_archivo = \"https://civitai.com/api/download/models/212479?type=Model&format=SafeTensor&size=full&fp=fp16\"\n",
        "aspect_ratio = \"1024*1024\"\n",
        "formato = \"safetensors\"\n",
        "\n",
        "if modificar_modelo:\n",
        "    resultado = modificar_json(nombre_archivo, link_archivo, aspect_ratio, formato)\n",
        "    print(resultado)\n",
        "\n",
        "model_url = link_archivo\n",
        "tokenCIVITAI = \"\"\n",
        "tokenHUGGINGFACE = \"\"\n",
        "\n",
        "model_sd = download_model_aria2(model_url, nombre_archivo, formato, tokenCIVITAI, tokenHUGGINGFACE)\n",
        "if model_sd:\n",
        "    print_colored(f\"Model downloaded: {model_sd}\", \"green\")\n",
        "else:\n",
        "    print_colored(\"Model download failed.\", \"red\")\n",
        "\n",
        "print_colored(\"[DeFooocus] Preparing...\", \"magenta\")\n",
        "\n",
        "theme = \"dark\"\n",
        "preset = \"default\"\n",
        "advenced_args = \"--share --attention-split --always-high-vram --disable-offload-from-vram --all-in-fp16\"\n",
        "\n",
        "if preset != \"default\":\n",
        "    args = f\"{advenced_args} --theme {theme} --preset {preset}\"\n",
        "else:\n",
        "    args = f\"{advenced_args} --theme {theme}\"\n",
        "\n",
        "args = f\"{args} {Args}\"\n",
        "\n",
        "print_colored(\"[DeFooocus] Starting...\", \"magenta\")\n",
        "!python entry_with_update.py {args}\n"
      ]
    }
  ]
}